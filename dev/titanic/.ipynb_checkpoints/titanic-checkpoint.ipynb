{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0f111cb4-8639-4418-a23c-4a9100c923ae",
    "_uuid": "421f8ddd9538e9295cd5465e0f828c83d445f93e",
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction\n",
    "This case study is about predicting which passengers survived the [sinking of the famous Titanic](https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Titanic). \n",
    "In our work, we will explore a dataset and establish a good prediction model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a985469-79f8-4b85-86e0-f4329ad1d64d",
    "_uuid": "85b53fff57969fba32fffb43fe3da95e1972181b",
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data description\n",
    "In this section, we load and explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c0c94c5a-07a6-4f8f-8276-188d4502e448",
    "_uuid": "434c433d8a0bf9956513c3744926966e7f8296ca",
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Libraries importing\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have 2 datasets:\n",
    "- \"train.csv\": contains informations about some passengers (multiple columns) and the fact that they survived or not (one column). You may download this dataset <a href=\"{{ site.baseurl }}/dev/titanic/data/train.csv\">here</a> in CSV format.\n",
    "- \"test.csv\": contains informations about some passengers (multiple columns) but without the survival information. You may download this dataset <a href=\"{{ site.baseurl }}/dev/titanic/data/test.csv\">here</a> in CSV format.\n",
    "\n",
    "In what follows, we mainly focus and use the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b709ed10-e333-40ea-8d15-26027d4e117d",
    "_uuid": "f51a6a1b9bc3ad281b3abd7cb38874a9477348ff",
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# This creates a pandas dataframe and assigns it to the titanic variable\n",
    "titanic = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Print the first five rows of the dataframe\n",
    "print(titanic.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are the different columns\n",
    "- <b>PassengerId</b>: Id of the passenger\n",
    "- <b>Pclass</b>: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- <b>Sex</b>: Sex\t\n",
    "- <b>Age</b>: Age in years\t\n",
    "- <b>Sibsp</b>: Number of siblings / spouses aboard the Titanic\t\n",
    "- <b>Parch</b>: Number of parents / children aboard the Titanic\t\n",
    "- <b>Ticket</b>: Ticket number\t\n",
    "- <b>Fare</b>: Passenger fare\t\n",
    "- <b>Cabin</b>: Cabin number\t\n",
    "- <b>Embarked</b>: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "- <b>Survival</b>: Survival (0 = No, 1 = Yes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hypothesis\n",
    "Let's think about the variables that might affect the outcome of survival:\n",
    "- Are women and children were more likely to survive? If yes, \"Age\" and \"Sex\" would be good predictors. \n",
    "- Knowing that first class cabins were closer to the deck of the ship, are passengers from the first class more likely to survive? If yes, passenger class \"pclass\" might affect the outcome. \"Fare\" is tied to passenger class and would probably have a strong correlation too.\n",
    "\n",
    "....................................................................................................\n",
    "Family size (the number of siblings and parents/children) will probably be correlated with survival one way or the other. That's because there would either be more people to help you, or more people to think about trying to save.\n",
    "\n",
    "There may be links between survival and columns like Ticket, Name, and Embarked (because people who boarded at certain ports may have had cabins closer or farther away from the top of the ship), .\n",
    "\n",
    "We call this step acquiring domain knowledge, and it's fairly important to most machine learning tasks. We're looking to engineer the features so that we maximize the information we have about what we're trying to predict.\n",
    "...................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data cleaning\n",
    "Let us have a look to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "# Summary on the dataframe\n",
    "print(len(titanic))\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All the numerical columns have indeed a count of 891 except the \"Age\" column that has a count of 714. \n",
    "This indicates that there are missing values (null, NA, or not a number).\n",
    "\n",
    "As we don't want to remove the rows with missing values, we choose to clean the data by filling in all of the missing values with the median of all the values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "titanic2 = titanic\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The \"Sex\" column is non-numeric, but it could be very informative. \n",
    "We will then convert it.\n",
    "First, we confirm that this column does not have empty values. then we make the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# What are the values for this column?\n",
    "print(titanic[\"Sex\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We do the same with the \"Embarked\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# What are the values for this column?\n",
    "print(titanic[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sklearn also has a helper that makes it easy to do cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#???\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The columns that can be used in the prediction\n",
    "predictorsAll = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Library for helping creating all combinations of sublists\n",
    "import itertools\n",
    "\n",
    "# Create all combinations of predictors\n",
    "myList = predictorsAll\n",
    "predictorCombinations = []\n",
    "for index in range(1, len(myList)+1):\n",
    "    for subset in itertools.combinations(myList, index):\n",
    "         predictorCombinations.append(list(subset))  \n",
    "            \n",
    "#print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Return the indexed of the sorted list\n",
    "def sort_list(myList):\n",
    "    return sorted(range(len(myList)), key=lambda i:myList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# not used\n",
    "def titanic_LinearRegression(predictors):\n",
    "    # Initialize our algorithm class\n",
    "    alg = LinearRegression()\n",
    "    # Generate cross-validation folds for the titanic data set\n",
    "    # It returns the row indices corresponding to train and test\n",
    "    # We set random_state to ensure we get the same splits every time we run this\n",
    "    kf = KFold(3, random_state=1)\n",
    "    predictions = []\n",
    "\n",
    "    for train, test in kf.split(titanic):\n",
    "        # The predictors we're using to train the algorithm  \n",
    "        # Note how we only take the rows in the train folds\n",
    "        train_predictors = (titanic[predictors].iloc[train,:])\n",
    "        # The target we're using to train the algorithm\n",
    "        train_target = titanic[\"Survived\"].iloc[train]\n",
    "        # Training the algorithm using the predictors and target\n",
    "        alg.fit(train_predictors, train_target)\n",
    "        # We can now make predictions on the test fold\n",
    "        test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "        predictions.append(test_predictions)\n",
    "\n",
    "    # The predictions are in three separate NumPy arrays  \n",
    "    # Concatenate them into a single array, along the axis 0 (the only 1 axis) \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    # Map predictions to outcomes (the only possible outcomes are 1 and 0)\n",
    "    predictions[predictions > .5] = 1\n",
    "    predictions[predictions <=.5] = 0\n",
    "    accuracy = len(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# not used\n",
    "def titanic_LogisticRegression(predictors):\n",
    "    # Initialize our algorithm\n",
    "    alg = LogisticRegression(random_state=1)\n",
    "    # Compute the accuracy score for all the cross-validation folds; this is much simpler than what we did before\n",
    "    scores = cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "    # Take the mean of the scores (because we have one for each fold)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def titanic_model_kf(predictors, nbKF, model, paramDict):\n",
    "    # List of algorithms\n",
    "    algs = []\n",
    "    \n",
    "    # Generate cross-validation folds for the titanic data set\n",
    "    # It returns the row indices corresponding to train and test\n",
    "    # We set random_state to ensure we get the same splits every time we run this\n",
    "    kf = KFold(nbKF, random_state=1)\n",
    "\n",
    "    # List of predictions\n",
    "    predictions = []\n",
    "\n",
    "    for train, test in kf.split(titanic):\n",
    "        # The predictors we're using to train the algorithm  \n",
    "        # Note how we only take the rows in the train folds\n",
    "        train_predictors = (titanic[predictors].iloc[train,:])\n",
    "        # The target we're using to train the algorithm\n",
    "        train_target = titanic[\"Survived\"].iloc[train]\n",
    "        \n",
    "        # Initialize our algorithm class\n",
    "        if(model == \"LinearRegression\"):\n",
    "            alg = LinearRegression()\n",
    "        elif(model == \"LogisticRegression\"):\n",
    "            alg = LogisticRegression()\n",
    "        elif(model == \"KNeighborsClassifier\"):\n",
    "            alg = KNeighborsClassifier(paramDict['n_neighbors'])\n",
    "        # Training the algorithm using the predictors and target\n",
    "        alg.fit(train_predictors, train_target)\n",
    "        algs.append(alg)\n",
    "        \n",
    "        # We can now make predictions on the test fold\n",
    "        #prediction = alg.predict(titanic[predictors])\n",
    "        #predictions.append(prediction)\n",
    "        \n",
    "        # We can now make predictions on the test fold\n",
    "        test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "        predictions.append(test_predictions)\n",
    "\n",
    "\n",
    "    # We have multiple predictions. Let us average them\n",
    "    #predictions = np.mean(predictions, axis=0)\n",
    "    \n",
    "    # The predictions are in three separate NumPy arrays  \n",
    "    # Concatenate them into a single array, along the axis 0 (the only 1 axis) \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    # Map predictions to outcomes (the only possible outcomes are 1 and 0)\n",
    "    predictions[predictions > .5] = 1\n",
    "    predictions[predictions <=.5] = 0\n",
    "    accuracy = len(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "    \n",
    "    # return the multiple algoriths and the accuracy\n",
    "    return [algs, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parch', 'Embarked'] :  0.5252525252525253\n",
      "['Parch'] :  0.5297418630751964\n",
      "['Pclass'] :  0.5432098765432098\n",
      "['SibSp', 'Parch'] :  0.547699214365881\n",
      "['SibSp', 'Parch', 'Embarked'] :  0.5488215488215489\n",
      "['Age', 'Embarked'] :  0.569023569023569\n",
      "['Age', 'Parch', 'Embarked'] :  0.5701459034792368\n",
      "['Age'] :  0.5735129068462402\n",
      "['Age', 'Parch'] :  0.5937149270482603\n",
      "['Age', 'SibSp', 'Embarked'] :  0.5993265993265994\n",
      "['Age', 'SibSp', 'Parch', 'Embarked'] :  0.6015712682379349\n",
      "['SibSp', 'Embarked'] :  0.6071829405162739\n",
      "['Pclass', 'SibSp', 'Embarked'] :  0.6083052749719416\n",
      "['Sex', 'Embarked'] :  0.611672278338945\n",
      "['Age', 'SibSp'] :  0.611672278338945\n",
      "['SibSp'] :  0.622895622895623\n",
      "['Age', 'SibSp', 'Parch'] :  0.6262626262626263\n",
      "['Embarked'] :  0.6363636363636364\n",
      "['Age', 'Fare'] :  0.6363636363636364\n",
      "['Pclass', 'Age', 'Fare'] :  0.6374859708193041\n",
      "['Age', 'Parch', 'Fare'] :  0.6374859708193041\n",
      "['Pclass', 'Parch', 'Embarked'] :  0.6386083052749719\n",
      "['Pclass', 'SibSp'] :  0.6408529741863075\n",
      "['Pclass', 'SibSp', 'Parch', 'Embarked'] :  0.6408529741863075\n",
      "['Pclass', 'Age', 'Embarked'] :  0.6442199775533108\n",
      "['Pclass', 'Parch', 'Fare'] :  0.6442199775533108\n",
      "['Sex', 'Parch'] :  0.6475869809203143\n",
      "['Pclass', 'SibSp', 'Fare'] :  0.6475869809203143\n",
      "['Pclass', 'Age', 'Parch', 'Fare'] :  0.6475869809203143\n",
      "['Pclass', 'Age', 'Parch', 'Embarked'] :  0.6475869809203143\n",
      "['Parch', 'Fare'] :  0.6487093153759821\n",
      "['Pclass', 'Age', 'Parch'] :  0.6498316498316499\n",
      "['Age', 'SibSp', 'Parch', 'Fare'] :  0.6531986531986532\n",
      "['Age', 'SibSp', 'Fare'] :  0.6565656565656566\n",
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] :  0.6565656565656566\n",
      "['Fare'] :  0.6576879910213244\n",
      "['Pclass', 'SibSp', 'Fare', 'Embarked'] :  0.6588103254769921\n",
      "['Pclass', 'Fare'] :  0.6599326599326599\n",
      "['Parch', 'Fare', 'Embarked'] :  0.6599326599326599\n",
      "['Pclass', 'Embarked'] :  0.6610549943883277\n",
      "['Pclass', 'Parch'] :  0.6621773288439955\n",
      "['Age', 'Fare', 'Embarked'] :  0.6621773288439955\n",
      "['Pclass', 'Age'] :  0.6632996632996633\n",
      "['SibSp', 'Parch', 'Fare'] :  0.6632996632996633\n",
      "['Pclass', 'Age', 'SibSp', 'Fare'] :  0.6632996632996633\n",
      "['Pclass', 'Age', 'Fare', 'Embarked'] :  0.6632996632996633\n",
      "['Age', 'SibSp', 'Fare', 'Embarked'] :  0.6632996632996633\n",
      "['Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.6632996632996633\n",
      "['SibSp', 'Fare'] :  0.6644219977553311\n",
      "['Pclass', 'Fare', 'Embarked'] :  0.6644219977553311\n",
      "['Pclass', 'SibSp', 'Parch', 'Fare'] :  0.6644219977553311\n",
      "['Age', 'Parch', 'Fare', 'Embarked'] :  0.6655443322109988\n",
      "['Pclass', 'Parch', 'Fare', 'Embarked'] :  0.6677890011223344\n",
      "['Fare', 'Embarked'] :  0.6689113355780022\n",
      "['SibSp', 'Fare', 'Embarked'] :  0.67003367003367\n",
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Embarked'] :  0.6711560044893379\n",
      "['Pclass', 'Age', 'Parch', 'Fare', 'Embarked'] :  0.6711560044893379\n",
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.6711560044893379\n",
      "['Pclass', 'Age', 'SibSp', 'Fare', 'Embarked'] :  0.6722783389450057\n",
      "['SibSp', 'Parch', 'Fare', 'Embarked'] :  0.6734006734006734\n",
      "['Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.6734006734006734\n",
      "['Pclass', 'Age', 'SibSp'] :  0.675645342312009\n",
      "['Pclass', 'Age', 'SibSp', 'Parch'] :  0.675645342312009\n",
      "['Pclass', 'SibSp', 'Parch'] :  0.6823793490460157\n",
      "['Sex', 'Age', 'Parch', 'Fare'] :  0.6879910213243546\n",
      "['Sex', 'Age', 'Fare', 'Embarked'] :  0.6891133557800224\n",
      "['Pclass', 'Sex', 'Age', 'Parch', 'Fare'] :  0.6891133557800224\n",
      "['Sex', 'Age', 'Parch', 'Fare', 'Embarked'] :  0.6891133557800224\n",
      "['Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.6891133557800224\n",
      "['Sex', 'Age', 'Fare'] :  0.691358024691358\n",
      "['Pclass', 'Sex', 'Age', 'Fare', 'Embarked'] :  0.691358024691358\n",
      "['Pclass', 'Sex', 'Age', 'Fare'] :  0.6924803591470258\n",
      "['Sex', 'Age', 'SibSp', 'Fare'] :  0.6924803591470258\n",
      "['Sex', 'Age', 'SibSp', 'Fare', 'Embarked'] :  0.6947250280583613\n",
      "['Pclass', 'Sex', 'Age', 'Parch', 'Fare', 'Embarked'] :  0.6947250280583613\n",
      "['Sex', 'Age', 'SibSp', 'Parch', 'Fare'] :  0.6958473625140292\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'] :  0.6958473625140292\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.6980920314253648\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Fare'] :  0.6992143658810326\n",
      "['Pclass', 'Age', 'SibSp', 'Embarked'] :  0.7003367003367004\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked'] :  0.7037037037037037\n",
      "['Sex', 'Age', 'SibSp', 'Parch', 'Embarked'] :  0.7239057239057239\n",
      "['Sex', 'Age', 'Embarked'] :  0.7317620650953984\n",
      "['Sex'] :  0.7362514029180696\n",
      "['Sex', 'Age', 'Parch', 'Embarked'] :  0.7373737373737373\n",
      "['Sex', 'Age', 'SibSp', 'Embarked'] :  0.7384960718294051\n",
      "['Sex', 'Fare'] :  0.7407407407407407\n",
      "['Sex', 'Parch', 'Fare', 'Embarked'] :  0.7407407407407407\n",
      "['Sex', 'Age', 'Parch'] :  0.7418630751964085\n",
      "['Pclass', 'Sex'] :  0.7429854096520763\n",
      "['Pclass', 'Sex', 'SibSp', 'Fare'] :  0.7441077441077442\n",
      "['Sex', 'Age', 'SibSp', 'Parch'] :  0.7441077441077442\n",
      "['Sex', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.7463524130190797\n",
      "['Sex', 'SibSp', 'Fare'] :  0.7474747474747475\n",
      "['Pclass', 'Sex', 'Age', 'Parch'] :  0.7474747474747475\n",
      "['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare'] :  0.7474747474747475\n",
      "['Pclass', 'Sex', 'Age'] :  0.7497194163860831\n",
      "['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked'] :  0.7497194163860831\n",
      "['Sex', 'SibSp', 'Parch', 'Fare'] :  0.7508417508417509\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked'] :  0.7508417508417509\n",
      "['Sex', 'Parch', 'Fare'] :  0.7519640852974186\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Embarked'] :  0.7519640852974186\n",
      "['Sex', 'Age'] :  0.7530864197530864\n",
      "['Sex', 'Fare', 'Embarked'] :  0.7530864197530864\n",
      "['Pclass', 'Sex', 'Age', 'Parch', 'Embarked'] :  0.7530864197530864\n",
      "['Pclass', 'Sex', 'Fare'] :  0.7575757575757576\n",
      "['Pclass', 'Sex', 'Age', 'Embarked'] :  0.7575757575757576\n",
      "['Pclass', 'Sex', 'Parch', 'Fare', 'Embarked'] :  0.7575757575757576\n",
      "['Sex', 'Age', 'SibSp'] :  0.7598204264870931\n",
      "['Pclass', 'Sex', 'SibSp', 'Fare', 'Embarked'] :  0.7598204264870931\n",
      "['Pclass', 'Sex', 'Age', 'SibSp'] :  0.7609427609427609\n",
      "['Pclass', 'Sex', 'Parch', 'Fare'] :  0.7609427609427609\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch'] :  0.7631874298540965\n",
      "['Pclass', 'Sex', 'Parch'] :  0.7643097643097643\n",
      "['Sex', 'Parch', 'Embarked'] :  0.7654320987654321\n",
      "['Sex', 'SibSp', 'Fare', 'Embarked'] :  0.7687991021324355\n",
      "['Sex', 'SibSp', 'Parch', 'Embarked'] :  0.7699214365881033\n",
      "['Pclass', 'Sex', 'SibSp'] :  0.7710437710437711\n",
      "['Pclass', 'Sex', 'Fare', 'Embarked'] :  0.7710437710437711\n",
      "['Pclass', 'Sex', 'Embarked'] :  0.7744107744107744\n",
      "['Pclass', 'Sex', 'SibSp', 'Parch'] :  0.7744107744107744\n",
      "['Pclass', 'Sex', 'SibSp', 'Embarked'] :  0.7755331088664422\n",
      "['Sex', 'SibSp', 'Embarked'] :  0.7789001122334456\n",
      "['Sex', 'SibSp', 'Parch'] :  0.7811447811447811\n",
      "['Pclass', 'Sex', 'Parch', 'Embarked'] :  0.7856341189674523\n",
      "['Sex', 'SibSp'] :  0.7912457912457912\n",
      "['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'] :  0.8002244668911336\n"
     ]
    }
   ],
   "source": [
    "accuracyList1 = []\n",
    "for combination in predictorCombinations:\n",
    "    #accuracyList1.append(titanic_model_kf(combination, 3, \"LinearRegression\", {})[1])\n",
    "    #accuracyList1.append(titanic_model_kf(combination, 3, \"LogisticRegression\", {})[1])\n",
    "    accuracyList1.append(titanic_model_kf(combination, 3, \"KNeighborsClassifier\", {'n_neighbors':5})[1])\n",
    "    \n",
    "#for index in range(len(predictorCombinations)):\n",
    "#    print(combinations[index], accuracyList1[index])\n",
    "\n",
    "for elementIndex in sort_list(accuracyList1):\n",
    "    print(combinations[elementIndex], \": \", accuracyList1[elementIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!!!!!!!!!!!!\n",
    "# Make predictions using the test set\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the data set\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "print(skl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
